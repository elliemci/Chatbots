{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN391apqMlPu+TivbZFyyzF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliemci/chatbots/blob/main/summarization_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrated summarization NLP task into a telegram chatbot.\n",
        "\n",
        "The user is able to choose a subject, the information about it is taken from Wikipedia and summarized using a model from Hugging Face library."
      ],
      "metadata": {
        "id": "-eYGBjoroXd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "00Ifh184S5s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04eb6627-32f3-4b4a-8533-a2c32243b8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pyTelegramBotAPI-4.14.0.tar.gz (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: pyTelegramBotAPI, wikipedia\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.14.0-py3-none-any.whl size=215250 sha256=dab3405a9adfe00c9ab9517511da583431a0ca9fc1212c2dc6ce8da0e1e7ad17\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/51/2d/24b40a366c85c37928d5aa36ddf257e5a79fad25e1ecd11b2c\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=90045ce06c1fb509ca117bc7657ef436fcca2f02b1fbde9ab8f690bb41b253c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built pyTelegramBotAPI wikipedia\n",
            "Installing collected packages: wikipedia, pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.14.0 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# install Python transformers(NLP) pyTelegramBotAPI(chatbot) and Wikipedia(data) libraries\n",
        "!pip install transformers pyTelegramBotAPI wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "import wikipedia\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "print(wikipedia.summary(\"Wikipedia\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2MliPJr0mTJ",
        "outputId": "545569a2-e257-43e0-8e88-8ea15664410d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Wikimedia Foundation, Inc. (WMF) is an American 501(c)(3) nonprofit organization headquartered in San Francisco, California, and registered as a charitable foundation under local laws. It is best known as the host platform for Wikipedia, the largest crowdsourced online encyclopedia in the world. The organization also hosts other related projects and MediaWiki, a wiki software.The Wikimedia Foundation was established in 2003 in St. Petersburg, Florida, by Jimmy Wales as a nonprofit way to fund Wikipedia, Wiktionary, and other crowdsourced wiki projects that had until then been hosted by Bomis, Wales's for-profit company. The Foundation finances itself mainly through millions of small donations from Wikipedia readers, collected through email campaigns and annual fundraising banners placed on Wikipedia and its sister projects. These are complemented by grants from philanthropic organizations and tech companies, and starting in 2022, by services income from Wikimedia Enterprise.\n",
            "The Foundation has grown rapidly throughout its existence. By 2022, it employed around 700 staff and contractors, with annual revenues of $155 million, annual expenses of $146 million, net assets of $240 million and a growing endowment, which surpassed $100 million in June 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['TELEGRAM_BOT_TOKEN'] = getpass('Enter your bot token: ')\n",
        "TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')\n",
        "\n",
        "# create the bot an instance of TeleBot setting the token\n",
        "bot = telebot.TeleBot(TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PvdkLI18vM",
        "outputId": "5a25f8f1-4330-4fd8-b840-2e1d80629520"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your bot token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load T5 transformer model from HuggingFace model hub\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "# instantiate the Hugging Face papiline class by passing the \"summarization\" task\n",
        "summarization_pipeline = pipeline(\"summarization\", model=\"t5-base\")\n",
        "\n",
        "# initalize bot state and subject\n",
        "state = 0\n",
        "subject = \"\"\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def message(message):\n",
        "\n",
        "    global state, subject\n",
        "    chat_id = message.chat.id\n",
        "\n",
        "    if state == 0:\n",
        "      bot.send_message(chat_id, \"Hi there! I'm ready get down to summarizing.\")\n",
        "      state = 1\n",
        "    elif state == 1:\n",
        "        subject = message.text\n",
        "        if subject == \"no\":\n",
        "          bot.send_message(chat_id, \"Goodbye!\")\n",
        "          state = 0\n",
        "        else:\n",
        "          bot.send_message(chat_id, \"Tell me a subject you want to summarize?\")\n",
        "          state = 2\n",
        "    elif state == 2:\n",
        "        subject = message.text\n",
        "        try:\n",
        "            wiki_text = wikipedia.summary(subject)\n",
        "        except wikipedia.exceptions.DisambiguationError as e:\n",
        "            bot.send_message(chat_id, \"Your topic is ambiguous, please provide more specific subject.\")\n",
        "            return\n",
        "        except wikipedia.exceptions.PageError as e:\n",
        "            bot.send_message(chat_id, \"I couldn't find a Wikipedia page on that subject.\")\n",
        "            return\n",
        "        summary = summarization_pipeline(wiki_text, min_length=10, max_length=50, do_sample=False)[0]['summary_text']\n",
        "        bot.send_message(chat_id, summary)\n",
        "        state = 3\n",
        "    elif state == 3:\n",
        "      bot.send_message(chat_id, \"You want me to keep summzrizing?\")\n",
        "      state = 1\n",
        "\n",
        "bot.polling()"
      ],
      "metadata": {
        "id": "qxIQ6Yue2lgy"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}