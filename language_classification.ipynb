{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSMbXATVDPXjk5xAmnVw0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliemci/chatbots/blob/main/language_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of the language of user's messages using BART\n",
        "\n",
        "BART is a denoising autoencoder, corrupting the input data and adding noise or masking some of the input values, for pretraining sequence-to-sequence models. It uses a Transformer-based neural machine translation architecture with a bidirectional encoder, like BERT, and a left-to-right decoder, like GPT;the encoder's attention mask is fully visible like BERT and the decoder's attention mask is causal, like GPT2.\n",
        "\n",
        "xlm-roberta-base-language-detection model is a fine-tuned version of XLM-RoBERTa model, a multilingual version of RoBERTa - Robustly optimized method for pretraining natural language processing systems that inproves on Bidirectional Encoder Representation from Transformers (BERT)"
      ],
      "metadata": {
        "id": "VbD2nL7ed5Pn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaqNyzR8d2st",
        "outputId": "6b86bf80-19d6-4164-c1be-8fb4a82701d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "AkXI1WEFm075"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# messages which language to be classified\n",
        "message1 = \"Se você insiste em classificar. Meu comportamento de anti-musical.\"\n",
        "message2 = \"Quand il me prend dans ses bras.\"\n",
        "message3 = \"Al mal tiempo, buena cara.\""
      ],
      "metadata": {
        "id": "NzuVZjxyUJFA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default model for a classification task is BART\n",
        "langclass_pipeline_bart = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "possible_languages = [\"french\", \"spanish\", \"portuguese\"]\n",
        "\n",
        "message_language1 = langclass_pipeline_bart(message1, possible_languages)[\"labels\"][0]\n",
        "probability1 = round(langclass_pipeline_bart(message1, possible_languages)[\"scores\"][0], 2)\n",
        "\n",
        "message_language2 = langclass_pipeline_bart(message2, possible_languages)[\"labels\"][0]\n",
        "probability2 = round(langclass_pipeline_bart(message2, possible_languages)[\"scores\"][0], 2)\n",
        "\n",
        "message_language3 = langclass_pipeline_bart(message3, possible_languages)[\"labels\"][0]\n",
        "probability3 = round(langclass_pipeline_bart(message3, possible_languages)[\"scores\"][0], 2)\n",
        "\n",
        "print(f\"Language detection with BART:\\n\")\n",
        "print(f\"The message \\\"{message1}\\\" is in {message_language1} with ptobability of {probability1}\")\n",
        "print(f\"The message \\\"{message2}\\\" is in {message_language2} with ptobability of {probability2}\")\n",
        "print(f\"The message \\\"{message3}\\\" is in {message_language3} with ptobability of {probability3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEePRtTLRG-k",
        "outputId": "e77f306e-52b1-47f2-fd53-b091a3d99099"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language detection with BART:\n",
            "\n",
            "The message \"Se você insiste em classificar. Meu comportamento de anti-musical.\" is in portuguese with ptobability of 0.43\n",
            "The message \"Quand il me prend dans ses bras.\" is in french with ptobability of 0.87\n",
            "The message \"Al mal tiempo, buena cara.\" is in spanish with ptobability of 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the pipelineclass object with xlm-roberta-base-language-detection,  which\n",
        "# is fine-tuned version of xlm-reberta-base on Language Identification dataset\n",
        "langclass_pipeline = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
        "\n",
        "# xlm-roberta-base-language-detection can be used as language detector supporting 20 languages\n",
        "languages = {\n",
        "    \"ar\": \"arabic\",\n",
        "    \"bg\": \"bulgarian\",\n",
        "    \"de\": \"german\",\n",
        "    \"el\": \"modern greek\",\n",
        "    \"en\": \"english\",\n",
        "    \"es\": \"spanish\",\n",
        "    \"fr\": \"french\",\n",
        "    \"hi\": \"hindi\",\n",
        "    \"it\": \"italian\",\n",
        "    \"ja\": \"japanese\",\n",
        "    \"nl\": \"dutch\",\n",
        "    \"pl\": \"polish\",\n",
        "    \"pt\": \"portuguese\",\n",
        "    \"ru\": \"russian\",\n",
        "    \"sw\": \"swahili\",\n",
        "    \"th\": \"thai\",\n",
        "    \"tr\": \"turkish\",\n",
        "    \"ur\": \"urdu\",\n",
        "    \"vi\": \"vietnamese\",\n",
        "    \"zh\": \"chinese\",\n",
        "}\n",
        "\n",
        "message_language1 = langclass_pipeline(message1)[0][\"label\"]\n",
        "probability1 = round(langclass_pipeline(message1)[0][\"score\"], 2)\n",
        "\n",
        "message_language2 = langclass_pipeline(message2)[0][\"label\"]\n",
        "probability2 = round(langclass_pipeline(message2)[0][\"score\"], 2)\n",
        "\n",
        "message_language3 = langclass_pipeline(message3)[0][\"label\"]\n",
        "probability3 = round(langclass_pipeline(message3)[0][\"score\"], 2)\n",
        "\n",
        "print(f\"Language detection with RoBERTa:\\n\")\n",
        "print(f\"The message \\\"{message1}\\\" is in {languages[message_language1]} with ptobability of {probability1}\")\n",
        "print(f\"The message \\\"{message2}\\\" is in {languages[message_language2]} with ptobability of {probability2}\")\n",
        "print(f\"The message \\\"{message3}\\\" is in {languages[message_language3]} with ptobability of {probability3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUk1fL2unG0I",
        "outputId": "4d65f05f-9be4-42e0-f520-6d65d755e0d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language detection with RoBERTa:\n",
            "\n",
            "The message \"Se você insiste em classificar. Meu comportamento de anti-musical.\" is in portuguese with ptobability of 0.99\n",
            "The message \"Quand il me prend dans ses bras.\" is in french with ptobability of 0.71\n",
            "The message \"Al mal tiempo, buena cara.\" is in spanish with ptobability of 0.99\n"
          ]
        }
      ]
    }
  ]
}